{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# EDA\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Data Understanding**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Data Collecting**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"Heart_Disease_Prediction (1).csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Exploratory Data Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# checking for null values\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = df.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# checking the duplicates values\n",
        "df.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = df.drop_duplicates()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "for col in df.columns:\n",
        "    df.loc[:, col] = encoder.fit_transform(df[col])\n",
        "\n",
        "# Convert all columns to numeric df type\n",
        "df = df.apply(pd.to_numeric)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Using Pearson Correlation\n",
        "plt.figure(figsize=(30, 30))\n",
        "cor = df.corr()\n",
        "sns.heatmap(data=cor, annot=True, cmap=\"coolwarm\", center=0, linewidths=0.5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Data Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df.drop([\"Heart Disease\"], axis=1)\n",
        "y = df[\"Heart Disease\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=123\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"Total # of sample in whole dataset: {len(X)}\")\n",
        "print(f\"Total # of sample in train dataset: {len(X_train)}\")\n",
        "print(f\"Total # of sample in test dataset: {len(X_test)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Assuming df is your DataFrame\n",
        "numerical_features = X.select_dtypes(include=[\"int\", \"float\"]).columns.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Initialize the StandardScaler object\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the scaler to the numerical features in the training set and transform them\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "\n",
        "# Transform the numerical features in the test set using the scaler fitted on the training set\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **ANN Modelling**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def checkpoint_callback(\n",
        "    filepath=\"best_model_checkpoint.h5\",\n",
        "    monitor=\"val_loss\",\n",
        "    mode=\"min\",\n",
        "    save_best_only=True,\n",
        "    verbose=1,\n",
        "):\n",
        "    checkpoint_callback = ModelCheckpoint(\n",
        "        filepath=filepath,\n",
        "        monitor=monitor,\n",
        "        mode=mode,\n",
        "        save_best_only=save_best_only,\n",
        "        verbose=verbose,\n",
        "    )\n",
        "    return checkpoint_callback\n",
        "\n",
        "\n",
        "# Define early stopping criteria\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor=\"val_loss\", patience=10, verbose=0, restore_best_weights=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "\n",
        "def create_model(input_size):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(64, input_dim=input_size, activation=\"relu\"))\n",
        "    model.add(Dense(32, activation=\"relu\"))\n",
        "    model.add(Dense(32, activation=\"relu\"))\n",
        "    model.add(Dense(32, activation=\"relu\"))\n",
        "    model.add(Dense(1, activation=\"sigmoid\"))\n",
        "    model.compile(optimizer=\"Adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "\n",
        "# Function to train the model\n",
        "def train_model(\n",
        "    model,\n",
        "    X_train,\n",
        "    y_train,\n",
        "    early_stopping_on=False,\n",
        "    checkpoint_on=False,\n",
        "    checkpoint_path=None,\n",
        "):\n",
        "    callbacks = []\n",
        "\n",
        "    # Define checkpoint callback\n",
        "    if checkpoint_on:\n",
        "        # Create dynamic checkpoint directory if it doesn't exist\n",
        "        # Add checkpoint callback\n",
        "        checkpoint_callback = ModelCheckpoint(\n",
        "            filepath=checkpoint_path, monitor=\"val_loss\", save_best_only=True\n",
        "        )\n",
        "        callbacks.append(checkpoint_callback)\n",
        "\n",
        "    # Add early stopping callback if enabled\n",
        "    if early_stopping_on:\n",
        "        callbacks.append(early_stopping)\n",
        "\n",
        "    start_time = time.time()\n",
        "    model.fit(\n",
        "        X_train,\n",
        "        y_train,\n",
        "        epochs=200,\n",
        "        batch_size=64,\n",
        "        validation_split=0.2,\n",
        "        callbacks=callbacks,\n",
        "    )\n",
        "    end_time = time.time()\n",
        "    return end_time - start_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the ANN model and its path\n",
        "ann_best_model_file_path = \"heart_failure/models/ANN_best_model.h5\"\n",
        "ann_model = create_model(X_train.shape[1])\n",
        "\n",
        "# Train the ANN model\n",
        "ann_training_time = train_model(\n",
        "    ann_model,\n",
        "    X_train,\n",
        "    y_train,\n",
        "    checkpoint_on=True,\n",
        "    checkpoint_path=ann_best_model_file_path,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **ANN Model Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "# Load a Keras model\n",
        "ann_best_model = load_model(ann_best_model_file_path)\n",
        "# Use the trained model to make predictions on the test data\n",
        "ann_predictions = ann_best_model.predict(X_test)\n",
        "\n",
        "# If your model outputs probabilities, you might need to convert them to class labels\n",
        "# For example, if the output is probability of class 1, you can set a threshold to classify as class 1\n",
        "threshold = 0.5\n",
        "ann_prediction_class = (ann_predictions > threshold).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Calculate accuracy\n",
        "ann_accuracy = accuracy_score(y_test, ann_prediction_class)\n",
        "# Calculate precision\n",
        "ann_precision = precision_score(y_test, ann_prediction_class)\n",
        "# Calculate recall\n",
        "ann_recall = recall_score(y_test, ann_prediction_class)\n",
        "# Calculate F1-score\n",
        "ann_f1 = f1_score(y_test, ann_prediction_class)\n",
        "\n",
        "print(\"Accuracy:\", ann_accuracy)\n",
        "print(\"Precision:\", ann_precision)\n",
        "print(\"Recall:\", ann_recall)\n",
        "print(\"F1-score:\", ann_f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "conf_matrix_ann = confusion_matrix(y_test, ann_prediction_class)\n",
        "\n",
        "# Plot the heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix_ann, annot=True, cmap='Blues', fmt='g', cbar=False)\n",
        "plt.title('Confusion Matrix - ANN')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **GA + ANN Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pygad\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from numpy.random import RandomState"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "seed = 1234\n",
        "state = RandomState(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def fitness_func(ga_instance, solution, solution_idx):\n",
        "    selected_features_indices = np.where(solution == 1)[0]\n",
        "    print(solution)\n",
        "    X_train_selected = X_train[:, selected_features_indices]\n",
        "    X_test_selected = X_test[:, selected_features_indices]\n",
        "\n",
        "    # Get the number of selected features\n",
        "    input_size = X_train_selected\n",
        "\n",
        "    model = create_model(input_size.shape[1])  # Pass input size here\n",
        "    model.fit(\n",
        "        X_train_selected,\n",
        "        y_train,\n",
        "        epochs=200,\n",
        "        batch_size=64,\n",
        "        validation_split=0.2,\n",
        "        callbacks=[early_stopping],\n",
        "        verbose=0,\n",
        "    )\n",
        "\n",
        "    accuracy = model.evaluate(X_test_selected, y_test, verbose=0)[1]\n",
        "    print(accuracy)\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def on_generation(ga_instance):\n",
        "    global last_fitness\n",
        "    print(\n",
        "        \"Generation = {generation}\".format(generation=ga_instance.generations_completed)\n",
        "    )\n",
        "    print(\"Fitness    = {fitness}\".format(fitness=ga_instance.best_solution()[1]))\n",
        "    print(f\"Change     = {ga_instance.best_solution()[1] - last_fitness}\")\n",
        "\n",
        "    last_fitness = ga_instance.best_solution()[1].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "last_fitness = 0\n",
        "num_generations = 50\n",
        "num_parents_mating = 4\n",
        "pop_size = 8\n",
        "num_features = X.shape[1]\n",
        "gene_space = state.randint(0, 2, num_features)\n",
        "parent_selection_type = \"sss\"\n",
        "crossover_type = \"single_point\"\n",
        "mutation_type = \"random\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create an instance of the GA class\n",
        "ga_instance = pygad.GA(\n",
        "    num_generations=num_generations,\n",
        "    num_parents_mating=num_parents_mating,\n",
        "    fitness_func=fitness_func,\n",
        "    on_generation=on_generation,\n",
        "    sol_per_pop=pop_size,\n",
        "    num_genes=num_features,\n",
        "    gene_space=gene_space,\n",
        "    parent_selection_type=parent_selection_type,\n",
        "    crossover_type=crossover_type,\n",
        "    mutation_type=mutation_type,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ga_instance.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ga_instance.plot_fitness()\n",
        "solution, solution_fitness, solution_idx = ga_instance.best_solution()\n",
        "print(\"Feature of the best solution : {solution}\".format(solution=solution))\n",
        "print(\n",
        "    \"Fitness value of the best solution = {solution_fitness}\".format(\n",
        "        solution_fitness=solution_fitness\n",
        "    )\n",
        ")\n",
        "print(\"Index of the best solution : {solution_idx}\".format(solution_idx=solution_idx))\n",
        "\n",
        "if ga_instance.best_solution_generation != -1:\n",
        "    print(\n",
        "        \"Best fitness value reached after {best_solution_generation} generations.\".format(\n",
        "            best_solution_generation=ga_instance.best_solution_generation\n",
        "        )\n",
        "    )\n",
        "print(f\"Number of features selected = {sum(solution)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract selected features based on global best position\n",
        "ga_selected_features = np.where(solution > 0.5)[0]\n",
        "# Train and evaluate model using selected features\n",
        "X_train_ga_selected = X_train[:, ga_selected_features]\n",
        "X_test_ga_selected = X_test[:, ga_selected_features]\n",
        "\n",
        "ga_ann_best_model_file_path = \"heart_failure/models/GA_ANN_best_model.h5\"\n",
        "ga_ann_model = create_model(X_train_ga_selected.shape[1])\n",
        "\n",
        "# Train the ANN model\n",
        "ga_ann_training_time = train_model(\n",
        "    ga_ann_model,\n",
        "    X_train_ga_selected,\n",
        "    y_train,\n",
        "    checkpoint_on=True,\n",
        "    checkpoint_path=ga_ann_best_model_file_path,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **GA + ANN Model Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Genetic Algorithm Selected Features Indices:\", ga_selected_features)\n",
        "print(\"Genetic Algorithm Selected Features:\", X.columns[ga_selected_features].tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ga_ann_best_model = load_model(ga_ann_best_model_file_path)\n",
        "ga_ann_prediction = ga_ann_best_model.predict(X_test_ga_selected)\n",
        "\n",
        "threshold = 0.5\n",
        "ga_ann_prediction_class = (ga_ann_prediction > threshold).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate accuracy\n",
        "ga_ann_accuracy = accuracy_score(y_test, ga_ann_prediction_class)\n",
        "\n",
        "# Calculate precision\n",
        "ga_ann_precision = precision_score(y_test, ga_ann_prediction_class)\n",
        "\n",
        "# Calculate recall\n",
        "ga_ann_recall = recall_score(y_test, ga_ann_prediction_class)\n",
        "\n",
        "# Calculate F1-score\n",
        "ga_ann_f1 = f1_score(y_test, ga_ann_prediction_class)\n",
        "\n",
        "print(\"Accuracy:\", ga_ann_accuracy)\n",
        "print(\"Precision:\", ga_ann_precision)\n",
        "print(\"Recall:\", ga_ann_recall)\n",
        "print(\"F1-score:\", ga_ann_f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "conf_matrix_ga_ann = confusion_matrix(y_test, ga_ann_prediction_class)\n",
        "\n",
        "# Plot the heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix_ga_ann, annot=True, cmap='Blues', fmt='g', cbar=False)\n",
        "plt.title('Confusion Matrix - GA + ANN')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **PSO + ANN Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Define PSO parameters\n",
        "num_particles = 10\n",
        "max_iter = 50\n",
        "w = 0.5\n",
        "c1 = 1.5\n",
        "c2 = 1.5\n",
        "\n",
        "# Initialize particles\n",
        "particles_position = np.random.rand(num_particles, X_train.shape[1])\n",
        "particles_velocity = np.random.uniform(-1, 1, size=(num_particles, X_train.shape[1]))\n",
        "particles_best_position = particles_position.copy()\n",
        "particles_best_fitness = np.zeros(num_particles)\n",
        "\n",
        "global_best_position = np.zeros(X_train.shape[1])\n",
        "global_best_fitness = float(\"-inf\")\n",
        "\n",
        "\n",
        "# Define fitness function\n",
        "def fitness_function(selected_features):\n",
        "    # Use selected features to train and evaluate the model\n",
        "    X_train_selected = X_train[:, selected_features.astype(bool)]\n",
        "    X_test_selected = X_test[:, selected_features.astype(bool)]\n",
        "    model = create_model(X_train_selected.shape[1])\n",
        "    model.fit(\n",
        "        X_train_selected,\n",
        "        y_train,\n",
        "        epochs=200,\n",
        "        batch_size=64,\n",
        "        validation_split=0.2,\n",
        "        callbacks=[early_stopping],\n",
        "        verbose=0,\n",
        "    )\n",
        "    accuracy = model.evaluate(X_test_selected, y_test, verbose=0)[1]\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "# Perform PSO optimization\n",
        "for iteration in range(max_iter):\n",
        "    print(\"Iteration:\", iteration)\n",
        "    for i in range(num_particles):\n",
        "        # Evaluate fitness for each particle\n",
        "        fitness = fitness_function(particles_position[i])\n",
        "        print(f\"Particle {i} fitness: {fitness}\")\n",
        "\n",
        "        # Update personal best\n",
        "        if fitness > particles_best_fitness[i]:\n",
        "            particles_best_fitness[i] = fitness\n",
        "            particles_best_position[i] = particles_position[i].copy()\n",
        "\n",
        "        # Update global best\n",
        "        if fitness > global_best_fitness:\n",
        "            global_best_fitness = fitness\n",
        "            global_best_position = particles_position[i].copy()\n",
        "\n",
        "    for i in range(num_particles):\n",
        "        r1 = random.random()\n",
        "        r2 = random.random()\n",
        "        cognitive_component = (\n",
        "            c1 * r1 * (particles_best_position[i] - particles_position[i])\n",
        "        )\n",
        "        social_component = c2 * r2 * (global_best_position - particles_position[i])\n",
        "        particles_velocity[i] = (\n",
        "            w * particles_velocity[i] + cognitive_component + social_component\n",
        "        )\n",
        "\n",
        "        # Apply thresholding for binary decision\n",
        "        particles_position[i] = 1 / (1 + np.exp(-particles_velocity[i]))\n",
        "\n",
        "        # Print global best fitness and position\n",
        "print(\"Global best fitness:\", global_best_fitness)\n",
        "print(\"Global best position:\", global_best_position)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract selected features based on global best position\n",
        "pso_selected_features = np.where(global_best_position > 0.45)[0]\n",
        "# Train and evaluate model using selected features\n",
        "X_train_pso_selected = X_train[:, pso_selected_features]\n",
        "X_test_pso_selected = X_test[:, pso_selected_features]\n",
        "\n",
        "pso_ann_best_model_file_path = \"heart_failure/models/PSO_ANN_best_model.h5\"\n",
        "pso_ann_model = create_model(X_train_pso_selected.shape[1])\n",
        "\n",
        "# Train the ANN model\n",
        "pso_ann_training_time = train_model(\n",
        "    pso_ann_model,\n",
        "    X_train_pso_selected,\n",
        "    y_train,\n",
        "    checkpoint_on=True,\n",
        "    checkpoint_path=pso_ann_best_model_file_path,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"PSO Selected Features Indices:\", pso_selected_features)\n",
        "print(\"PSO Selected Features:\", X.columns[pso_selected_features].tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load a Keras model\n",
        "pso_ann_best_model = load_model(pso_ann_best_model_file_path)\n",
        "# Use the trained model to make predictions on the test data\n",
        "pso_ann_prediction = pso_ann_best_model.predict(X_test_pso_selected)\n",
        "\n",
        "# If your model outputs probabilities, you might need to convert them to class labels\n",
        "# For example, if the output is probability of class 1, you can set a threshold to classify as class 1\n",
        "threshold = 0.5\n",
        "pso_ann_prediction_class = (pso_ann_prediction > threshold).astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **PSO + ANN Model Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "pso_ann_accuracy = accuracy_score(y_test, pso_ann_prediction_class)\n",
        "\n",
        "# Calculate precision\n",
        "pso_ann_precision = precision_score(y_test, pso_ann_prediction_class)\n",
        "\n",
        "# Calculate recall\n",
        "pso_ann_recall = recall_score(y_test, pso_ann_prediction_class)\n",
        "\n",
        "# Calculate F1-score\n",
        "pso_ann_f1 = f1_score(y_test, pso_ann_prediction_class)\n",
        "\n",
        "print(\"Accuracy:\", pso_ann_accuracy)\n",
        "print(\"Precision:\", pso_ann_precision)\n",
        "print(\"Recall:\", pso_ann_recall)\n",
        "print(\"F1-score:\", pso_ann_f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "conf_matrix_pso_ann = confusion_matrix(y_test, pso_ann_prediction_class)\n",
        "\n",
        "# Plot the heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix_pso_ann, annot=True, cmap='Blues', fmt='g', cbar=False)\n",
        "plt.title('Confusion Matrix - ANN')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Result Comparison**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "pso_selected_features= ['Age', 'Chest pain type', 'BP', 'Cholesterol', 'FBS over 120', 'EKG results', 'Exercise angina', 'ST depression', 'Slope of ST', 'Number of vessels fluro', 'Thallium']\n",
        "\n",
        "ga_selected_features= ['Age', 'Chest pain type', 'EKG results', 'Exercise angina', 'ST depression', 'Slope of ST', 'Number of vessels fluro', 'Thallium']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define the features\n",
        "all_features = ['Age', 'Sex', 'Chest pain type', 'BP', 'Cholesterol',\n",
        "                'FBS over 120', 'EKG results', 'Max HR', 'Exercise angina',\n",
        "                'ST depression', 'Slope of ST', 'Number of vessels fluro',\n",
        "                'Thallium']\n",
        "\n",
        "# Create an empty DataFrame to store the information\n",
        "comparison_data = []\n",
        "\n",
        "# Iterate through all features\n",
        "for feature in all_features:\n",
        "    pso_selected = 'Yes' if feature in pso_selected_features else 'No'\n",
        "    ga_selected = 'Yes' if feature in ga_selected_features else 'No'\n",
        "    comparison_data.append({'Feature': feature,\n",
        "                            'PSO Selected': pso_selected,\n",
        "                            'GA Selected': ga_selected})\n",
        "\n",
        "# Create a DataFrame from the data\n",
        "comparison_table = pd.DataFrame(comparison_data)\n",
        "\n",
        "# Display the comparison table\n",
        "comparison_table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plotting the execution times\n",
        "\n",
        "\n",
        "models = [\"ANN\", \"GA+ANN\", \"PSO+ANN\"]\n",
        "execution_times = [ann_training_time, ga_ann_training_time, pso_ann_training_time]\n",
        "\n",
        "# Print the execution times for each model\n",
        "print(\"Execution time for ANN model:\", ann_training_time)\n",
        "print(\"Execution time for GA+ANN model:\", ga_ann_training_time)\n",
        "print(\"Execution time for PSO+ANN model:\", pso_ann_training_time)\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.bar(models, execution_times, color=[\"blue\", \"green\", \"orange\"])\n",
        "\n",
        "plt.xlabel(\"Models\")\n",
        "plt.ylabel(\"Execution Time (seconds)\")\n",
        "plt.title(\"Execution Time Comparison between Different Models\")\n",
        "plt.grid(axis=\"y\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define model names\n",
        "model_names = [\"ANN\", \"ANN + GA\", \"ANN + PSO\"]\n",
        "\n",
        "# Define MSE, MAE, and R^2 values for all models\n",
        "accuracy = [ann_accuracy, ga_ann_accuracy, pso_ann_accuracy]\n",
        "precision = [ann_precision, ga_ann_precision, pso_ann_precision]\n",
        "recall = [ann_recall, ga_ann_recall, pso_ann_recall]\n",
        "f1 = [ann_f1, ga_ann_f1, pso_ann_f1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create subplots\n",
        "fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
        "\n",
        "# Plot Accuracy\n",
        "axes[0, 0].bar(model_names, accuracy, color=[\"blue\", \"orange\", \"green\"])\n",
        "axes[0, 0].set_ylabel(\"Accuracy\")\n",
        "axes[0, 0].set_title(\"Comparison of Accuracy\")\n",
        "axes[0, 0].set_ylim(min(accuracy) - 0.01, max(accuracy) + 0.01)  # Adjust y-axis limits\n",
        "\n",
        "# Plot Precision\n",
        "axes[0, 1].bar(model_names, precision, color=[\"blue\", \"orange\", \"green\"])\n",
        "axes[0, 1].set_ylabel(\"Precision\")\n",
        "axes[0, 1].set_title(\"Comparison of Precision\")\n",
        "axes[0, 1].set_ylim(min(precision) - 0.01, max(precision) + 0.01)  # Adjust y-axis limits\n",
        "\n",
        "# Plot Recall\n",
        "axes[1, 0].bar(model_names, recall, color=[\"blue\", \"orange\", \"green\"])\n",
        "axes[1, 0].set_ylabel(\"Recall\")\n",
        "axes[1, 0].set_title(\"Comparison of Recall\")\n",
        "axes[1, 0].set_ylim(min(recall) - 0.01, max(recall) + 0.01)  # Adjust y-axis limits\n",
        "\n",
        "# Plot F1 Score\n",
        "axes[1, 1].bar(model_names, f1, color=[\"blue\", \"orange\", \"green\"])\n",
        "axes[1, 1].set_ylabel(\"F1\")\n",
        "axes[1, 1].set_title(\"Comparison of F1\")\n",
        "axes[1, 1].set_ylim(min(f1) - 0.01, max(f1) + 0.01)  # Adjust y-axis limits\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Add a table\n",
        "table_data = [\n",
        "    [\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\"],\n",
        "    [model_names[0], ann_accuracy, ann_precision, ann_recall, ann_f1],\n",
        "    [model_names[1], ga_ann_accuracy, ga_ann_precision, ga_ann_recall, ga_ann_f1],\n",
        "    [model_names[2], pso_ann_accuracy, pso_ann_precision, pso_ann_recall, pso_ann_f1]\n",
        "]\n",
        "\n",
        "# Create a DataFrame\n",
        "comparison_table = pd.DataFrame(table_data[1:], columns=table_data[0])\n",
        "\n",
        "# Sort the table by Accuracy in descending order and apply background gradient\n",
        "comparison_table_sorted = comparison_table.sort_values(by='Accuracy', ascending=False)\n",
        "styled_comparison_table = comparison_table_sorted.style.background_gradient(cmap='Blues')\n",
        "\n",
        "styled_comparison_table\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def plot_confusion_matrix(ax, y_true, y_pred, title):\n",
        "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "    sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='g', cbar=False, ax=ax)\n",
        "    ax.set_title(title)\n",
        "    ax.set_xlabel('Predicted Label')\n",
        "    ax.set_ylabel('True Label')\n",
        "\n",
        "# Create subplots\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "# Assuming you have three different predictions\n",
        "# ann_prediction_class, ga_ann_prediction_class, pso_ann_prediction_class\n",
        "# for ANN, GA-ANN, and PSO-ANN classifiers respectively\n",
        "\n",
        "plot_confusion_matrix(axes[0], y_test, ann_prediction_class, 'ANN')\n",
        "plot_confusion_matrix(axes[1], y_test, ga_ann_prediction_class, 'GA-ANN')\n",
        "plot_confusion_matrix(axes[2], y_test, pso_ann_prediction_class, 'PSO-ANN')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
